The code is designed to work with LunarLanderContinuous-v2 from OpenAI Gym.<br>
Please install OpenAI Gym environment on your computer first and then run this software.<br>
<br><br>
For more details about each algorithm, please read the following article:<br>
*T. Tanaka, H. Malki and M. Cescon. Linear Quadratic Tracking with Reinforcement Learning Based Reference Trajectory Optimization for the Lunar Hopper in Simulated Environment. IEEE Access https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9645562
<br>
LQT control algorithm is implemented in 'heuristic' function in the lunar_lander_LQT.py. <br>
RL is a reinforcement learning code, and LQT-TRO is a LQT control with learning-based reference trajectory optimization.<br>
<br>
Note: This code was developed based on an open-source code developed by Clayton Thorrez (https://github.com/cthorrez/ml-fun/tree/master/ddpg). Special thanks to him.<br>
<br><br>
Thanks!<br>
tskTNK
